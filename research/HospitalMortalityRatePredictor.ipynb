{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to End Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy.stats import chi2\n",
    "import ipywidgets as widgets\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, roc_auc_score, precision_score, f1_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Display Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_excel(\"Healthcare_cat_dataset.xlsx\")\n",
    "data = original_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1177 entries, 0 to 1176\n",
      "Data columns (total 53 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   group               1177 non-null   int64  \n",
      " 1   ID                  1177 non-null   int64  \n",
      " 2   outcome             1176 non-null   float64\n",
      " 3   age                 1177 non-null   int64  \n",
      " 4   gender              1177 non-null   int64  \n",
      " 5   BMI_cat             1177 non-null   int64  \n",
      " 6   hypertensive        1177 non-null   int64  \n",
      " 7   atrialfibrillation  1177 non-null   int64  \n",
      " 8   CHD with no MI      1177 non-null   int64  \n",
      " 9   diabetes            1177 non-null   int64  \n",
      " 10  deficiencyanemias   1177 non-null   int64  \n",
      " 11  depression          1177 non-null   int64  \n",
      " 12  Hyperlipemia        1177 non-null   int64  \n",
      " 13  Renal failure       1177 non-null   int64  \n",
      " 14  COPD                1177 non-null   int64  \n",
      " 15  heart rate at       1177 non-null   int64  \n",
      " 16  Pulse rate cat      1161 non-null   float64\n",
      " 17  Sys_cat             1177 non-null   int64  \n",
      " 18  Diastolic           1177 non-null   int64  \n",
      " 19  respiratory cat     1177 non-null   int64  \n",
      " 20  temp_cat            1177 non-null   int64  \n",
      " 21  SP O2               1177 non-null   int64  \n",
      " 22  urine_cat           1177 non-null   int64  \n",
      " 23  hemocrit_cat        1177 non-null   int64  \n",
      " 24  RBC_Cat             1177 non-null   int64  \n",
      " 25  mch_cat             1177 non-null   int64  \n",
      " 26  mchc_Cat            1177 non-null   int64  \n",
      " 27  mcv_cta             1177 non-null   int64  \n",
      " 28  rdw_cat             1177 non-null   int64  \n",
      " 29  leukocytes_cat      1177 non-null   int64  \n",
      " 30  platelets_cat       1177 non-null   int64  \n",
      " 31  neutriphil_cat      1177 non-null   int64  \n",
      " 32  Basophil_cat        1177 non-null   int64  \n",
      " 33  Lympho_cat          1177 non-null   int64  \n",
      " 34  PT_cat(sec)         1177 non-null   int64  \n",
      " 35  INR_cat             1177 non-null   int64  \n",
      " 36  NT_cat              1177 non-null   int64  \n",
      " 37  CK_cat              1177 non-null   int64  \n",
      " 38  Creatinine_cat      1177 non-null   int64  \n",
      " 39  UN_cat              1177 non-null   int64  \n",
      " 40  Glu_cat             1177 non-null   int64  \n",
      " 41  potas_cat           1177 non-null   int64  \n",
      " 42  sodium_cat          1177 non-null   int64  \n",
      " 43  cal_cat             1177 non-null   int64  \n",
      " 44  chloride_cat        1177 non-null   int64  \n",
      " 45  anion_cat           1177 non-null   int64  \n",
      " 46  Mag_cat             1177 non-null   int64  \n",
      " 47  ph_cat              1177 non-null   int64  \n",
      " 48  Biccarbon_cat       1177 non-null   int64  \n",
      " 49  metcat              1177 non-null   int64  \n",
      " 50  lactic_cat          1177 non-null   int64  \n",
      " 51  pco2_cat            1177 non-null   int64  \n",
      " 52  ef_cat              1177 non-null   int64  \n",
      "dtypes: float64(2), int64(51)\n",
      "memory usage: 487.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>ID</th>\n",
       "      <th>outcome</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>BMI_cat</th>\n",
       "      <th>hypertensive</th>\n",
       "      <th>atrialfibrillation</th>\n",
       "      <th>CHD with no MI</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>...</th>\n",
       "      <th>cal_cat</th>\n",
       "      <th>chloride_cat</th>\n",
       "      <th>anion_cat</th>\n",
       "      <th>Mag_cat</th>\n",
       "      <th>ph_cat</th>\n",
       "      <th>Biccarbon_cat</th>\n",
       "      <th>metcat</th>\n",
       "      <th>lactic_cat</th>\n",
       "      <th>pco2_cat</th>\n",
       "      <th>ef_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1176.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "      <td>1177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.299065</td>\n",
       "      <td>150778.120646</td>\n",
       "      <td>0.135204</td>\n",
       "      <td>74.055225</td>\n",
       "      <td>1.525064</td>\n",
       "      <td>0.445200</td>\n",
       "      <td>0.717927</td>\n",
       "      <td>0.451147</td>\n",
       "      <td>0.085811</td>\n",
       "      <td>0.421410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486831</td>\n",
       "      <td>0.651657</td>\n",
       "      <td>0.800340</td>\n",
       "      <td>0.672048</td>\n",
       "      <td>0.734070</td>\n",
       "      <td>0.532710</td>\n",
       "      <td>0.029737</td>\n",
       "      <td>0.213254</td>\n",
       "      <td>0.283772</td>\n",
       "      <td>0.570093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.458043</td>\n",
       "      <td>29034.669513</td>\n",
       "      <td>0.342087</td>\n",
       "      <td>13.434061</td>\n",
       "      <td>0.499584</td>\n",
       "      <td>0.497199</td>\n",
       "      <td>0.450200</td>\n",
       "      <td>0.497819</td>\n",
       "      <td>0.280204</td>\n",
       "      <td>0.493995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500039</td>\n",
       "      <td>0.476648</td>\n",
       "      <td>0.399915</td>\n",
       "      <td>0.469667</td>\n",
       "      <td>0.442015</td>\n",
       "      <td>0.499141</td>\n",
       "      <td>0.169932</td>\n",
       "      <td>0.409780</td>\n",
       "      <td>0.451019</td>\n",
       "      <td>0.495273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>100213.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>125603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>151901.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>176048.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>199952.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             group             ID      outcome          age       gender  \\\n",
       "count  1177.000000    1177.000000  1176.000000  1177.000000  1177.000000   \n",
       "mean      1.299065  150778.120646     0.135204    74.055225     1.525064   \n",
       "std       0.458043   29034.669513     0.342087    13.434061     0.499584   \n",
       "min       1.000000  100213.000000     0.000000    19.000000     1.000000   \n",
       "25%       1.000000  125603.000000     0.000000    65.000000     1.000000   \n",
       "50%       1.000000  151901.000000     0.000000    77.000000     2.000000   \n",
       "75%       2.000000  176048.000000     0.000000    85.000000     2.000000   \n",
       "max       2.000000  199952.000000     1.000000    99.000000     2.000000   \n",
       "\n",
       "           BMI_cat  hypertensive  atrialfibrillation  CHD with no MI  \\\n",
       "count  1177.000000   1177.000000         1177.000000     1177.000000   \n",
       "mean      0.445200      0.717927            0.451147        0.085811   \n",
       "std       0.497199      0.450200            0.497819        0.280204   \n",
       "min       0.000000      0.000000            0.000000        0.000000   \n",
       "25%       0.000000      0.000000            0.000000        0.000000   \n",
       "50%       0.000000      1.000000            0.000000        0.000000   \n",
       "75%       1.000000      1.000000            1.000000        0.000000   \n",
       "max       1.000000      1.000000            1.000000        1.000000   \n",
       "\n",
       "          diabetes  ...      cal_cat  chloride_cat    anion_cat      Mag_cat  \\\n",
       "count  1177.000000  ...  1177.000000   1177.000000  1177.000000  1177.000000   \n",
       "mean      0.421410  ...     0.486831      0.651657     0.800340     0.672048   \n",
       "std       0.493995  ...     0.500039      0.476648     0.399915     0.469667   \n",
       "min       0.000000  ...     0.000000      0.000000     0.000000     0.000000   \n",
       "25%       0.000000  ...     0.000000      0.000000     1.000000     0.000000   \n",
       "50%       0.000000  ...     0.000000      1.000000     1.000000     1.000000   \n",
       "75%       1.000000  ...     1.000000      1.000000     1.000000     1.000000   \n",
       "max       1.000000  ...     1.000000      1.000000     1.000000     1.000000   \n",
       "\n",
       "            ph_cat  Biccarbon_cat       metcat   lactic_cat     pco2_cat  \\\n",
       "count  1177.000000    1177.000000  1177.000000  1177.000000  1177.000000   \n",
       "mean      0.734070       0.532710     0.029737     0.213254     0.283772   \n",
       "std       0.442015       0.499141     0.169932     0.409780     0.451019   \n",
       "min       0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000       0.000000     0.000000     0.000000     0.000000   \n",
       "50%       1.000000       1.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000       1.000000     0.000000     0.000000     1.000000   \n",
       "max       1.000000       1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            ef_cat  \n",
       "count  1177.000000  \n",
       "mean      0.570093  \n",
       "std       0.495273  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 53 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent_variable = 'outcome'\n",
    "hypothesis_testing_metric = 'p_Value_Chi'\n",
    "hypithesis_feature_header = 'Feature'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Non Significant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>BMI_cat</th>\n",
       "      <th>hypertensive</th>\n",
       "      <th>atrialfibrillation</th>\n",
       "      <th>CHD with no MI</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>deficiencyanemias</th>\n",
       "      <th>depression</th>\n",
       "      <th>...</th>\n",
       "      <th>cal_cat</th>\n",
       "      <th>chloride_cat</th>\n",
       "      <th>anion_cat</th>\n",
       "      <th>Mag_cat</th>\n",
       "      <th>ph_cat</th>\n",
       "      <th>Biccarbon_cat</th>\n",
       "      <th>metcat</th>\n",
       "      <th>lactic_cat</th>\n",
       "      <th>pco2_cat</th>\n",
       "      <th>ef_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   outcome  age  gender  BMI_cat  hypertensive  atrialfibrillation  \\\n",
       "0      0.0   72       1        0             0                   0   \n",
       "1      0.0   75       2        0             0                   0   \n",
       "2      0.0   83       2        1             0                   0   \n",
       "3      0.0   43       2        0             0                   0   \n",
       "4      0.0   75       2        0             1                   0   \n",
       "\n",
       "   CHD with no MI  diabetes  deficiencyanemias  depression  ...  cal_cat  \\\n",
       "0               0         1                  1           0  ...        0   \n",
       "1               0         0                  1           0  ...        0   \n",
       "2               0         0                  1           0  ...        0   \n",
       "3               0         0                  0           0  ...        1   \n",
       "4               0         0                  1           0  ...        1   \n",
       "\n",
       "   chloride_cat  anion_cat  Mag_cat  ph_cat  Biccarbon_cat  metcat  \\\n",
       "0             0          1        0       1              0       0   \n",
       "1             1          1        1       1              0       0   \n",
       "2             1          1        1       1              0       0   \n",
       "3             0          1        1       1              0       0   \n",
       "4             1          1        0       1              0       0   \n",
       "\n",
       "   lactic_cat  pco2_cat  ef_cat  \n",
       "0           0         1       1  \n",
       "1           0         0       1  \n",
       "2           0         0       0  \n",
       "3           0         0       1  \n",
       "4           0         0       1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['ID', 'group'], axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for NUll Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outcome', 'Pulse rate cat']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = data.isnull().sum()\n",
    "df1 = df1[df1 != 0]\n",
    "impute_columns = df1.index.to_list()\n",
    "impute_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing with Mode as value is binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_null_with_mode(df, columns):\n",
    "    for column in columns:\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_null_with_mode(data, impute_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization w.r.t Dependent Vatiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as utl\n",
    "\n",
    "df = data.drop([dependent_variable,'age'], axis=1)\n",
    "features = df.columns\n",
    "plot_viz = utl.get_plot_viz()\n",
    "widgets.interact(plot_viz, feature=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derive New feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for anemia & blood pressure\n",
    "data['derivedAnemia'] = np.where((data['deficiencyanemias'] == 1) & (data['RBC_Cat'] == 1), 1, 0)\n",
    "data['derivedInflammation'] = np.where((data['neutriphil_cat'] == 1) & (data['Lympho_cat'] == 1), 1, 0)\n",
    "features = ['derivedAnemia', 'deficiencyanemias', 'RBC_Cat', 'derivedInflammation', 'neutriphil_cat', 'Lympho_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot p-Values \n",
    "data.drop(dependent_variable, axis=1, inplace=True)\n",
    "eval_result = utl.perform_hypothesis_test(dependent_variable, data.columns).sort_values([hypothesis_testing_metric], ascending=True)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,10]\n",
    "colors = [\"red\" if i > 0.05 else \"#40A944\" for i in eval_result.p_Value_Chi]\n",
    "plt.barh(eval_result.Feature, eval_result.p_Value_Chi, color = colors) \n",
    "# setting label of y-axis\n",
    "plt.ylabel(\"Features\") \n",
    "# setting label of x-axis\n",
    "plt.xlabel(\"p-Values\")\n",
    "plt.title(\"Horizontal bar graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original_data[dependent_variable].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=1, random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=1, random_state=42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X, y = pipeline.fit_resample(data.drop(dependent_variable, axis=1), data[dependent_variable])\n",
    "data_upsampled = pd.concat([pd.DataFrame(y), pd.DataFrame(X)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling with different Algos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, roc_auc_score, precision_score, f1_score\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from preventing overfitting we will do seperate data into train and test\n",
    "\n",
    "y = mdf_upsampled['outcome']\n",
    "X = mdf_upsampled.drop(columns = [\"outcome\"], axis = 1)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y,test_size = 0.3,random_state = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logReg = LogisticRegression()\n",
    "res = model_logReg.fit(X_train, y_train)\n",
    "pred= model_logReg.predict(X_test)\n",
    "pred_logi = model_logReg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "y_pred_logi = np.where(model_logReg.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logiDF = pd.DataFrame(data=[accuracy_score(y_test, y_pred_logi), recall_score(y_test, y_pred_logi),\n",
    "                   precision_score(y_test, y_pred_logi), f1_score(y_test, y_pred_logi, average='binary'),\n",
    "                   roc_auc_score(y_test, y_pred_logi)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\"])\n",
    "\n",
    "logiDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn= KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred_knn= knn.predict(X_test)\n",
    "pred_knn = knn.predict_proba(X_test)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(y_test, y_pred_knn), recall_score(y_test, y_pred_knn),\n",
    "                   precision_score(y_test, y_pred_knn),  f1_score(y_test, y_pred_knn, average='binary'),\n",
    "                   roc_auc_score(y_test, y_pred_knn)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "\n",
    "y_pred_dtree = dtree.predict(X_test)\n",
    "pred_dtree = dtree.predict_proba(X_test)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(y_test, y_pred_dtree), recall_score(y_test, y_pred_dtree),\n",
    "                   precision_score(y_test, y_pred_dtree),  f1_score(y_test, y_pred_dtree, average='binary'),\n",
    "                   roc_auc_score(y_test, y_pred_dtree)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM ( Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='linear', probability=True)\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svclassifier.predict(X_test)\n",
    "pred_svm = svclassifier.predict_proba(X_test)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(y_test, y_pred_svm), recall_score(y_test, y_pred_svm),\n",
    "                   precision_score(y_test, y_pred_svm),  f1_score(y_test, y_pred_svm, average='binary'),\n",
    "                   roc_auc_score(y_test, y_pred_svm)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforestClassifier = RandomForestClassifier(n_estimators = 100)\n",
    "rforestClassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rforestClassifier.predict(X_test)\n",
    "pred_rf = rforestClassifier.predict_proba(X_test)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(y_test, y_pred_rf), recall_score(y_test, y_pred_rf),\n",
    "                   precision_score(y_test, y_pred_rf),  f1_score(y_test, y_pred_rf, average='binary'),\n",
    "                   roc_auc_score(y_test, y_pred_rf)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbClassifier = XGBClassifier()\n",
    "xgbClassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xgbClassifier.predict(X_test)\n",
    "pred_xgb = xgbClassifier.predict_proba(X_test)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(y_test, y_pred_xgb), recall_score(y_test, y_pred_xgb),\n",
    "                   precision_score(y_test, y_pred_xgb),  f1_score(y_test, y_pred_xgb, average='binary'),\n",
    "                   roc_auc_score(y_test, y_pred_xgb)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Models Evaluation using ROC Curve Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# roc curve for models\n",
    "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_logi[:,1], pos_label=1)\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_test, pred_knn[:,1], pos_label=1)\n",
    "fpr3, tpr3, thresh3 = roc_curve(y_test, pred_dtree[:,1], pos_label=1)\n",
    "fpr4, tpr4, thresh4 = roc_curve(y_test, pred_svm[:,1], pos_label=1)\n",
    "fpr5, tpr5, thresh5 = roc_curve(y_test, pred_rf[:,1], pos_label=1)\n",
    "fpr6, tpr6, thresh6 = roc_curve(y_test, pred_xgb[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')\n",
    "plt.plot(fpr2, tpr2, linestyle='solid',color='green', label='KNN')\n",
    "plt.plot(fpr3, tpr3, linestyle='dashed',color='red', label='DTree')\n",
    "plt.plot(fpr4, tpr4, linestyle='solid',color='brown', label='SVM')\n",
    "plt.plot(fpr5, tpr5, linestyle='dashdot',color='black', label='RF')\n",
    "plt.plot(fpr6, tpr6, linestyle='-.',color='blue', label='XGB')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='-', color='pink')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC',dpi=300)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from matplotlib import pyplot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chi2 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationResult = PerformHypothesisTest('outcome', X_train.columns)\n",
    "ns_df_sorted = evaluationResult.sort_values(['p_Value_Chi'], ascending = True).head(15)\n",
    "ns_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_significant_columns = SelectKBest(mutual_info_classif,k= 15)\n",
    "sel_significant_columns.fit(X_train,y_train)\n",
    "\n",
    "names = X_train.columns.values[sel_significant_columns.get_support()]\n",
    "scores = sel_significant_columns.scores_[sel_significant_columns.get_support()]\n",
    "names_scores = list(zip(names, scores))\n",
    "ns_df = pd.DataFrame(data = names_scores, columns=['Feat_names', 'F_Scores'])\n",
    "#Sort the dataframe for better visualization\n",
    "ns_df_sorted = ns_df.sort_values(['F_Scores', 'Feat_names'], ascending = [False, True])\n",
    "ns_df_sorted\n",
    "\n",
    "plt.figure(figsize = (20,8))\n",
    "ns_df_sorted.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "extra_tree_forest = ExtraTreesClassifier(n_estimators = 100, criterion ='gini', max_features = 15)\n",
    "extra_tree_forest.fit(X, y)\n",
    "\n",
    "feature_importance = extra_tree_forest.feature_importances_\n",
    "\n",
    "\n",
    "feature_importance_normalized = np.std([tree.feature_importances_ \n",
    "                                        for tree in extra_tree_forest.estimators_],\n",
    "                                        axis = 0)\n",
    "features = pd.Series(feature_importance_normalized, index=X.columns).nlargest(15)\n",
    "\n",
    "etf_features = pd.DataFrame(features)\n",
    "\n",
    "etf_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg_rfe_model = RFE(estimator=logreg,n_features_to_select=15)\n",
    "logreg_model_fit = logreg_rfe_model.fit(X_train,y_train)\n",
    "logreg_feat_index = pd.Series(data = logreg_model_fit.ranking_, index = X_train.columns)\n",
    "logreg_feat_rfe = logreg_feat_index[logreg_feat_index==1].index\n",
    "\n",
    "logreg_selected_features = pd.DataFrame(logreg_feat_rfe)\n",
    "logreg_selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm_lin=SVC(kernel='linear')\n",
    "svm_rfe_model=RFE(estimator=svm_lin,n_features_to_select=15)\n",
    "svm_rfe_model_fit=svm_rfe_model.fit(X_train,y_train)\n",
    "feat_index = pd.Series(data = svm_rfe_model_fit.ranking_, index = X_train.columns)\n",
    "signi_feat_rfe = feat_index[feat_index==1].index\n",
    "\n",
    "svm_selected_features = pd.DataFrame(signi_feat_rfe)\n",
    "svm_selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf_rfe_model=RFE(estimator=clf,n_features_to_select=15)\n",
    "clf_model_fit=clf_rfe_model.fit(X_train,y_train)\n",
    "feat_index = pd.Series(data = clf_model_fit.ranking_, index = X_train.columns)\n",
    "signi_feat_rfe = feat_index[feat_index==1].index\n",
    "\n",
    "rf_selected_features = pd.DataFrame(signi_feat_rfe)\n",
    "rf_selected_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linearReg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
